# ğŸ“‹ Workflow ç¼–å†™æ•™ç¨‹

æœ¬æ•™ç¨‹å°†æŒ‡å¯¼ä½ å¦‚ä½•åœ¨ DataFlow-Agent é¡¹ç›®ä¸­åˆ›å»ºå’Œç¼–å†™ Workflowï¼ˆå·¥ä½œæµï¼‰ã€‚

## ç›®å½•

1. [å‡†å¤‡å·¥ä½œ](#1-å‡†å¤‡å·¥ä½œ)
2. [ä½¿ç”¨ CLI å¿«é€Ÿåˆ›å»º](#2-ä½¿ç”¨-cli-å¿«é€Ÿåˆ›å»º)
3. [Workflow åŸºç¡€ç»“æ„](#3-workflow-åŸºç¡€ç»“æ„)
4. [State å’Œ Request å®šä¹‰](#4-state-å’Œ-request-å®šä¹‰)
5. [Agent åˆ›å»ºæ–¹å¼](#5-agent-åˆ›å»ºæ–¹å¼)
6. [å·¥å…·ç³»ç»Ÿ](#6-å·¥å…·ç³»ç»Ÿ)
7. [èŠ‚ç‚¹ç¼–å†™](#7-èŠ‚ç‚¹ç¼–å†™)
8. [å›¾æ„å»º](#8-å›¾æ„å»º)
9. [å®Œæ•´ç¤ºä¾‹](#9-å®Œæ•´ç¤ºä¾‹)
10. [è°ƒè¯•å’Œæµ‹è¯•](#10-è°ƒè¯•å’Œæµ‹è¯•)
11. [æœ€ä½³å®è·µ](#11-æœ€ä½³å®è·µ)

---

## 1. å‡†å¤‡å·¥ä½œ

### 1.1 äº†è§£é¡¹ç›®ç»“æ„

```
dataflow_agent/
â”œâ”€â”€ workflow/          # Workflow å®šä¹‰ç›®å½•
â”‚   â”œâ”€â”€ wf_*.py       # Workflow æ–‡ä»¶ï¼ˆå¿…é¡»ä»¥ wf_ å¼€å¤´ï¼‰
â”‚   â””â”€â”€ registry.py   # Workflow æ³¨å†Œä¸­å¿ƒ
â”œâ”€â”€ agentroles/       # Agent è§’è‰²å®šä¹‰
â”œâ”€â”€ state.py          # State å’Œ Request å®šä¹‰
â”œâ”€â”€ graphbuilder/     # å›¾æ„å»ºå™¨
â”œâ”€â”€ templates/        # ä»£ç ç”Ÿæˆæ¨¡æ¿
â””â”€â”€ cli.py           # CLI å‘½ä»¤å·¥å…·
```

### 1.2 æ ¸å¿ƒæ¦‚å¿µ

- **Workflow**: ç”±å¤šä¸ªèŠ‚ç‚¹ï¼ˆNodeï¼‰å’Œè¾¹ï¼ˆEdgeï¼‰ç»„æˆçš„æœ‰å‘å›¾
- **State**: åœ¨ Workflow ä¸­æµè½¬çš„çŠ¶æ€å¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯
- **Request**: State ä¸­çš„è¯·æ±‚å¯¹è±¡ï¼ŒåŒ…å«ç”¨æˆ·è¾“å…¥å’Œé…ç½®
- **Node**: Workflow ä¸­çš„å¤„ç†å•å…ƒï¼Œé€šå¸¸è°ƒç”¨ Agent æ‰§è¡Œä»»åŠ¡
- **Agent**: å…·æœ‰ç‰¹å®šè§’è‰²çš„ LLM è°ƒç”¨å°è£…ï¼Œè´Ÿè´£å®Œæˆå…·ä½“ä»»åŠ¡
- **Tool**: Agent å¯ä»¥ä½¿ç”¨çš„å·¥å…·å‡½æ•°ï¼ˆå‰ç½®å·¥å…·å’Œåç½®å·¥å…·ï¼‰

### 1.3 å‘½åè§„èŒƒ

- **Workflow æ–‡ä»¶**: å¿…é¡»ä»¥ `wf_` å¼€å¤´ï¼Œå¦‚ `wf_my_workflow.py`
- **æ³¨å†Œåç§°**: å»æ‰ `wf_` å‰ç¼€ï¼Œå¦‚ `wf_pipeline_write.py` æ³¨å†Œä¸º `"pipeline_write"`
- **State ç±»**: ä»¥ `State` ç»“å°¾ï¼Œå¦‚ `MyWorkflowState`
- **Request ç±»**: ä»¥ `Request` ç»“å°¾ï¼Œå¦‚ `MyWorkflowRequest`

---

## 2. ä½¿ç”¨ CLI å¿«é€Ÿåˆ›å»º

DataFlow-Agent æä¾›äº† `dfa create` å‘½ä»¤æ¥å¿«é€Ÿç”Ÿæˆå„ç§ç»„ä»¶ã€‚

### 2.1 åˆ›å»º Workflow

```bash
# åˆ›å»ºä¸€ä¸ªæ–°çš„ workflow
dfa create --wf_name my_workflow

# è¿™å°†ç”Ÿæˆï¼š
# - dataflow_agent/workflow/wf_my_workflow.py  (workflow æºç )
# - tests/test_my_workflow.py                  (æµ‹è¯•æ–‡ä»¶)
```

### 2.2 åˆ›å»º Agent

```bash
# åˆ›å»ºä¸€ä¸ªæ–°çš„ agent
dfa create --agent_name my_agent

# è¿™å°†ç”Ÿæˆï¼š
# - dataflow_agent/agentroles/my_agent_agent.py
```

### 2.3 åˆ›å»º State

```bash
# åˆ›å»ºè‡ªå®šä¹‰ State å’Œ Request
dfa create --state_name my_workflow

# è¿™å°†ç”Ÿæˆï¼š
# - dataflow_agent/states/my_workflow_state.py
```

### 2.4 åˆ›å»º Prompt Template

```bash
# åˆ›å»º prompt æ¨¡æ¿
dfa create --prompt_name my_agent

# è¿™å°†ç”Ÿæˆï¼š
# - dataflow_agent/promptstemplates/resources/pt_my_agent_repo.py
```

### 2.5 å…¶ä»–åˆ›å»ºé€‰é¡¹

```bash
# åˆ›å»º Gradio é¡µé¢
dfa create --gradio_name my_page

# åˆ›å»º Agent-as-Tool
dfa create --agent_as_tool_name my_tool_agent
```

---

## 3. Workflow åŸºç¡€ç»“æ„

### 3.1 åŸºæœ¬æ¨¡æ¿

```python
"""
my_workflow workflow
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
åŠŸèƒ½æè¿°ï¼šç®€è¦è¯´æ˜å·¥ä½œæµåŠŸèƒ½
"""

from __future__ import annotations
from dataflow_agent.state import MainState  # æˆ–ä½ çš„è‡ªå®šä¹‰ State
from dataflow_agent.graphbuilder.graph_builder import GenericGraphBuilder
from dataflow_agent.workflow.registry import register
from dataflow_agent.logger import get_logger

log = get_logger(__name__)

@register("my_workflow")  # æ³¨å†Œåç§°ï¼ˆä¸å« wf_ å‰ç¼€ï¼‰
def create_my_workflow_graph() -> GenericGraphBuilder:
    """
    Workflow å·¥å‚å‡½æ•°
    
    é€šè¿‡ dfa run --wf my_workflow è°ƒç”¨
    """
    builder = GenericGraphBuilder(
        state_model=MainState,      # State ç±»å‹
        entry_point="step1"         # å…¥å£èŠ‚ç‚¹åç§°
    )
    
    # ========== å·¥å…·å®šä¹‰ ==========
    # åœ¨è¿™é‡Œå®šä¹‰å‰ç½®å·¥å…·å’Œåç½®å·¥å…·
    
    # ========== èŠ‚ç‚¹å®šä¹‰ ==========
    # åœ¨è¿™é‡Œå®šä¹‰èŠ‚ç‚¹å‡½æ•°
    
    # ========== å›¾æ„å»º ==========
    # åœ¨è¿™é‡Œæ·»åŠ èŠ‚ç‚¹å’Œè¾¹
    
    return builder
```

### 3.2 æ³¨å†Œæœºåˆ¶

ä½¿ç”¨ `@register` è£…é¥°å™¨å°† Workflow æ³¨å†Œåˆ°å…¨å±€æ³¨å†Œä¸­å¿ƒï¼š

```python
from dataflow_agent.workflow.registry import register

@register("my_workflow")  # æ³¨å†Œåç§°
def create_my_workflow_graph() -> GenericGraphBuilder:
    # ...
    pass
```

æ³¨å†Œåå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è°ƒç”¨ï¼š

```python
from dataflow_agent.workflow import run_workflow

# è¿è¡Œ workflow
result = await run_workflow("my_workflow", state)
```

---

## 4. State å’Œ Request å®šä¹‰

### 4.1 ç»§æ‰¿ä½“ç³»

æ‰€æœ‰ State å’Œ Request éƒ½åº”è¯¥ç»§æ‰¿è‡ªåŸºç±»ï¼š

```python
from dataclasses import dataclass, field
from dataflow_agent.state import MainState, MainRequest

# ==================== Request ====================
@dataclass
class MyWorkflowRequest(MainRequest):
    """è‡ªå®šä¹‰è¯·æ±‚å‚æ•°"""
    # ç»§æ‰¿ MainRequest çš„æ‰€æœ‰å­—æ®µï¼š
    # - language: str = "en"
    # - chat_api_url: str
    # - api_key: str
    # - model: str = "gpt-4o"
    # - target: str = ""
    
    # æ·»åŠ è‡ªå®šä¹‰å­—æ®µ
    input_data: str = ""
    config_param: str = "default"
    max_retries: int = 3

# ==================== State ====================
@dataclass
class MyWorkflowState(MainState):
    """è‡ªå®šä¹‰çŠ¶æ€"""
    # ç»§æ‰¿ MainState çš„æ‰€æœ‰å­—æ®µï¼š
    # - request: MainRequest
    # - messages: List[BaseMessage]
    # - agent_results: Dict[str, Any]
    # - temp_data: Dict[str, Any]
    
    # é‡å†™ request ç±»å‹
    request: MyWorkflowRequest = field(default_factory=MyWorkflowRequest)
    
    # æ·»åŠ è‡ªå®šä¹‰å­—æ®µ
    processing_result: dict = field(default_factory=dict)
    current_step: str = "start"
    intermediate_data: list = field(default_factory=list)
```

### 4.2 ä½¿ç”¨ CLI åˆ›å»º

```bash
# å¿«é€Ÿåˆ›å»º State å’Œ Request
dfa create --state_name my_workflow

# ç”Ÿæˆçš„æ–‡ä»¶ä¼šåŒ…å«åŸºæœ¬ç»“æ„ï¼Œä½ åªéœ€æ·»åŠ è‡ªå®šä¹‰å­—æ®µ
```

### 4.3 State å­—æ®µè¯´æ˜

**MainRequest æ ¸å¿ƒå­—æ®µ**:
- `language`: ç”¨æˆ·åå¥½è¯­è¨€ï¼ˆ"en" | "zh"ï¼‰
- `chat_api_url`: LLM API ç«¯ç‚¹
- `api_key`: API å¯†é’¥
- `model`: æ¨¡å‹åç§°ï¼ˆå¦‚ "gpt-4o"ï¼‰
- `target`: ä»»åŠ¡æè¿°

**MainState æ ¸å¿ƒå­—æ®µ**:
- `request`: è¯·æ±‚å¯¹è±¡
- `messages`: æ¶ˆæ¯å†å²ï¼ˆLangChain æ ¼å¼ï¼‰
- `agent_results`: Agent æ‰§è¡Œç»“æœå­—å…¸
- `temp_data`: ä¸´æ—¶æ•°æ®å­˜å‚¨

---

## 5. Agent åˆ›å»ºæ–¹å¼

### 5.1 æ–°çš„ç­–ç•¥æ¨¡å¼

é¡¹ç›®å¼•å…¥äº†ç­–ç•¥æ¨¡å¼ï¼Œæä¾›å¤šç§ä¾¿æ·çš„ Agent åˆ›å»ºå‡½æ•°ï¼š

```python
from dataflow_agent.agentroles import (
    create_simple_agent,   # ç®€å•æ¨¡å¼
    create_react_agent,    # ReAct æ¨¡å¼ï¼ˆå¸¦éªŒè¯ï¼‰
    create_graph_agent,    # å›¾æ¨¡å¼ï¼ˆå¸¦å·¥å…·è°ƒç”¨ï¼‰
    create_vlm_agent,      # è§†è§‰è¯­è¨€æ¨¡å‹æ¨¡å¼
)
```

### 5.2 ç®€å•æ¨¡å¼ Agent

é€‚ç”¨äºå•æ¬¡ LLM è°ƒç”¨çš„åœºæ™¯ï¼š

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    """ä½¿ç”¨ç®€å•æ¨¡å¼åˆ›å»º Agent"""
    agent = create_simple_agent(
        name="my_agent",           # Agent åç§°ï¼ˆå¿…é¡»å·²æ³¨å†Œï¼‰
        model_name="gpt-4o",       # æ¨¡å‹åç§°
        temperature=0.7,           # é‡‡æ ·æ¸©åº¦ (0.0-1.0)
        max_tokens=4096,           # æœ€å¤§ token æ•°
        parser_type="json",        # è§£æå™¨ç±»å‹: "json" | "xml" | "text"
    )
    
    # æ‰§è¡Œ Agent
    state = await agent.execute(state)
    
    # è·å–ç»“æœ
    result = state.agent_results.get("my_agent", {}).get("results", {})
    
    return state
```

### 5.3 ReAct æ¨¡å¼ Agent

é€‚ç”¨äºéœ€è¦éªŒè¯å’Œé‡è¯•çš„åœºæ™¯ï¼š

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    """ä½¿ç”¨ ReAct æ¨¡å¼åˆ›å»º Agent"""
    agent = create_react_agent(
        name="my_agent",
        model_name="gpt-4o",
        temperature=0.1,
        max_retries=3,             # æœ€å¤§é‡è¯•æ¬¡æ•°
        parser_type="json",
        # validators=[...],        # å¯é€‰ï¼šè‡ªå®šä¹‰éªŒè¯å™¨
    )
    
    state = await agent.execute(state)
    return state
```

### 5.4 å›¾æ¨¡å¼ Agent

é€‚ç”¨äºéœ€è¦è°ƒç”¨å·¥å…·çš„åœºæ™¯ï¼š

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    """ä½¿ç”¨å›¾æ¨¡å¼åˆ›å»º Agentï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰"""
    from dataflow_agent.toolkits.tool_manager import get_tool_manager
    
    agent = create_graph_agent(
        name="my_agent",
        model_name="gpt-4o",
        temperature=0.2,
        tool_mode="auto",          # å·¥å…·è°ƒç”¨æ¨¡å¼: "auto" | "none" | "required"
    )
    
    state = await agent.execute(state)
    return state
```

### 5.5 VLM æ¨¡å¼ Agent

é€‚ç”¨äºå¤„ç†å›¾åƒçš„åœºæ™¯ï¼š

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    """ä½¿ç”¨ VLM æ¨¡å¼åˆ›å»º Agent"""
    agent = create_vlm_agent(
        name="my_agent",
        model_name="gpt-4-vision-preview",
        temperature=0.1,
        vlm_mode="understanding",      # 'understanding' | 'generation' | 'edit'
        image_detail="high",           # 'low' | 'high' | 'auto'
        max_image_size=(2048, 2048),
    )
    
    state = await agent.execute(state)
    return state
```

### 5.6 å¹¶è¡Œæ¨¡å¼ Agent

é€‚ç”¨äºéœ€è¦æ‰¹é‡å¤„ç†å¤šæ¡æ•°æ®çš„åœºæ™¯ï¼š

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    """ä½¿ç”¨å¹¶è¡Œæ¨¡å¼åˆ›å»º Agent"""
    agent = create_parallel_agent(
        name="my_agent",
        model_name="gpt-4o",
        temperature=0.3,
        concurrency_limit=3,           # å¹¶è¡Œåº¦é™åˆ¶ï¼Œé»˜è®¤5
        parser_type="json",
    )
    
    state = await agent.execute(state)
    return state
```

#### å¹¶è¡Œæ¨¡å¼çš„æ•°æ®å‡†å¤‡

å¹¶è¡Œæ¨¡å¼ä¼šè‡ªåŠ¨æ£€æµ‹å‰ç½®å·¥å…·ç»“æœä¸­çš„åˆ—è¡¨æ•°æ®ï¼Œæ”¯æŒä¸‰ç§æ–¹å¼ï¼š

**æ–¹å¼ 1: å‰ç½®å·¥å…·ç›´æ¥è¿”å›åˆ—è¡¨**

```python
@builder.pre_tool("items", "my_agent")
def get_items(state: MyWorkflowState):
    """è¿”å›éœ€è¦å¹¶è¡Œå¤„ç†çš„æ•°æ®åˆ—è¡¨"""
    return [
        {"text": "ç¬¬ä¸€æ¡æ•°æ®", "id": 1},
        {"text": "ç¬¬äºŒæ¡æ•°æ®", "id": 2},
        {"text": "ç¬¬ä¸‰æ¡æ•°æ®", "id": 3},
    ]
```

**æ–¹å¼ 2: ä½¿ç”¨ parallel_items å­—æ®µ**

```python
@builder.pre_tool("data", "my_agent")
def get_data(state: MyWorkflowState):
    """è¿”å›åŒ…å« parallel_items çš„å­—å…¸"""
    return {
        "parallel_items": [
            {"text": "æ•°æ®1"},
            {"text": "æ•°æ®2"},
        ],
        "context": "å…±äº«ä¸Šä¸‹æ–‡ä¿¡æ¯"  # ä¼šè¢«æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å…±äº«
    }
```

**æ–¹å¼ 3: ä»»æ„åˆ—è¡¨å­—æ®µï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰**

```python
@builder.pre_tool("batch_data", "my_agent")
def get_batch_data(state: MyWorkflowState):
    """è¿”å›åŒ…å«åˆ—è¡¨å­—æ®µçš„å­—å…¸"""
    return {
        "items": [  # ä¼šè¢«è‡ªåŠ¨æ£€æµ‹ä¸ºå¹¶è¡Œæ•°æ®
            {"name": "item1"},
            {"name": "item2"},
        ],
        "config": {"mode": "fast"}  # ä¼šè¢«æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å…±äº«
    }
```

#### å¹¶è¡Œç»“æœå¤„ç†

å¹¶è¡Œæ¨¡å¼æ‰§è¡Œåï¼Œç»“æœä¼šåŒ…å«åœ¨ `parallel_results` å­—æ®µä¸­ï¼š

```python
async def process_parallel_results(state: MyWorkflowState) -> MyWorkflowState:
    """å¤„ç†å¹¶è¡Œæ‰§è¡Œç»“æœ"""
    result = state.agent_results.get("my_agent", {}).get("results", {})
    
    # è·å–æ‰€æœ‰å¹¶è¡Œç»“æœ
    parallel_results = result.get("parallel_results", [])
    total_processed = result.get("total_processed", 0)
    
    log.info(f"å…±å¤„ç† {total_processed} æ¡æ•°æ®")
    
    # èšåˆç»“æœ
    aggregated = {
        "success_count": sum(1 for r in parallel_results if not r.get("error")),
        "error_count": sum(1 for r in parallel_results if r.get("error")),
        "results": parallel_results
    }
    
    state.temp_data["aggregated_results"] = aggregated
    return state
```

### 5.6 ä½¿ç”¨é…ç½®å¯¹è±¡

ä¹Ÿå¯ä»¥ä½¿ç”¨é…ç½®å¯¹è±¡åˆ›å»º Agentï¼š

```python
from dataflow_agent.agentroles import create_agent
from dataflow_agent.agentroles.cores.configs import SimpleConfig, ReactConfig

# æ–¹å¼ 1: ä½¿ç”¨ SimpleConfig
config = SimpleConfig(
    model_name="gpt-4o",
    temperature=0.7,
    max_tokens=4096,
    parser_type="json",
)
agent = create_agent(name="my_agent", config=config)

# æ–¹å¼ 2: ä½¿ç”¨ ReactConfig
config = ReactConfig(
    model_name="gpt-4o",
    temperature=0.1,
    max_retries=3,
    parser_type="json",
)
agent = create_agent(name="my_agent", config=config)
```

---

## 6. å·¥å…·ç³»ç»Ÿ

> âš ï¸ **é‡è¦æç¤º**ï¼š`@builder.pre_tool()` å’Œ `@builder.post_tool()` è£…é¥°å™¨çš„ç¬¬äºŒä¸ªå‚æ•°ï¼ˆroleï¼‰åº”è¯¥å¡«å†™ **Agent çš„ role_name**ï¼Œè€Œä¸æ˜¯ workflow ä¸­çš„èŠ‚ç‚¹åç§°ï¼è¿™æ˜¯å› ä¸º Agent åœ¨æ‰§è¡Œæ—¶ä¼šé€šè¿‡ `self.role_name` ä» ToolManager ä¸­è·å–å¯¹åº”çš„å·¥å…·ã€‚

### 6.1 å‰ç½®å·¥å…·ï¼ˆPre-Toolï¼‰

å‰ç½®å·¥å…·åœ¨ Agent æ‰§è¡Œå‰è¿è¡Œï¼Œç”¨äºæ”¶é›†ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶æ³¨å…¥åˆ° prompt ä¸­ã€‚

#### å®šä¹‰å‰ç½®å·¥å…·

```python
@builder.pre_tool("placeholder_name", "agent_role_name")  # â† ç¬¬äºŒä¸ªå‚æ•°æ˜¯ Agent çš„ role_name
def my_pre_tool(state: MyWorkflowState):
    """
    å‰ç½®å·¥å…·å‡½æ•°
    
    Args:
        state: å½“å‰çŠ¶æ€å¯¹è±¡
        
    Returns:
        ä»»ä½•å¯åºåˆ—åŒ–çš„æ•°æ®ï¼ˆå­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å­—å…¸ç­‰ï¼‰
    """
    return state.request.input_data
```

#### å‚æ•°è¯´æ˜

- **ç¬¬ä¸€ä¸ªå‚æ•°**: Prompt æ¨¡æ¿ä¸­çš„å ä½ç¬¦åç§°
- **ç¬¬äºŒä¸ªå‚æ•°**: **Agent çš„ role_name**ï¼ˆä¸æ˜¯èŠ‚ç‚¹åç§°ï¼ï¼‰

#### æ­£ç¡®ç¤ºä¾‹ âœ…

```python
# å‡è®¾ä½ çš„ Agent çš„ role_name æ˜¯ "processor"
async def process_node(state: MyWorkflowState) -> MyWorkflowState:
    agent = create_simple_agent(
        name="processor",  # â† è¿™æ˜¯ Agent çš„ role_name
        model_name="gpt-4o",
    )
    state = await agent.execute(state)
    return state

# å‰ç½®å·¥å…·åº”è¯¥ç»‘å®šåˆ° Agent çš„ role_name
@builder.pre_tool("user_input", "processor")  # âœ… ä½¿ç”¨ Agent çš„ role_name
def get_user_input(state: MyWorkflowState):
    return state.request.target

@builder.pre_tool("context", "processor")  # âœ… ä½¿ç”¨ Agent çš„ role_name
def get_context(state: MyWorkflowState):
    return {
        "history": state.messages,
        "previous_results": state.agent_results
    }
```

#### é”™è¯¯ç¤ºä¾‹ âŒ

```python
# âŒ é”™è¯¯ï¼šç»‘å®šåˆ°èŠ‚ç‚¹åç§°è€Œä¸æ˜¯ Agent çš„ role_name
@builder.pre_tool("user_input", "process_node")  # âŒ è¿™æ˜¯èŠ‚ç‚¹åç§°ï¼Œä¸æ˜¯ role_name
def get_user_input(state: MyWorkflowState):
    return state.request.target

# è¿™æ ·ä¼šå¯¼è‡´å·¥å…·æ— æ³•è¢« Agent è·å–åˆ°ï¼
```

#### å·¥ä½œåŸç†è¯´æ˜

```python
# 1. åœ¨ workflow ä¸­å®šä¹‰å·¥å…·æ—¶ï¼Œç»‘å®šåˆ° Agent çš„ role_name
@builder.pre_tool("input", "my_agent")  # "my_agent" æ˜¯ Agent çš„ role_name

# 2. GenericGraphBuilder å°†å·¥å…·æ³¨å†Œåˆ° ToolManager
# ToolManager.register_pre_tool(name="input", role="my_agent", func=...)

# 3. Agent æ‰§è¡Œæ—¶ï¼Œé€šè¿‡è‡ªå·±çš„ role_name è·å–å·¥å…·
class MyAgent(BaseAgent):
    @property
    def role_name(self):
        return "my_agent"  # â† å¿…é¡»åŒ¹é…
    
    async def execute_pre_tools(self, state):
        # ä½¿ç”¨ self.role_name è·å–å·¥å…·
        results = await self.tool_manager.execute_pre_tools(self.role_name)
        # è¿™é‡Œä¼šè·å–åˆ°æ‰€æœ‰ç»‘å®šåˆ° "my_agent" çš„å‰ç½®å·¥å…·
```

åœ¨ Prompt æ¨¡æ¿ä¸­ä½¿ç”¨ï¼š

```jinja2
# task_prompt_for_my_agent.jinja
ç”¨æˆ·è¾“å…¥: {{ user_input }}

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{{ context }}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯å®Œæˆä»»åŠ¡ã€‚
```

### 6.2 åç½®å·¥å…·ï¼ˆPost-Toolï¼‰

åç½®å·¥å…·æ˜¯ Agent åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å¯ä»¥è°ƒç”¨çš„å·¥å…·å‡½æ•°ã€‚

> âš ï¸ **åŒæ ·é‡è¦**ï¼š`@builder.post_tool()` çš„å‚æ•°ä¹Ÿåº”è¯¥æ˜¯ **Agent çš„ role_name**ï¼Œè€Œä¸æ˜¯èŠ‚ç‚¹åç§°ï¼

#### å®šä¹‰åç½®å·¥å…·

```python
from pydantic import BaseModel, Field
from langchain.tools import tool

class MyToolInput(BaseModel):
    """å·¥å…·è¾“å…¥å‚æ•°å®šä¹‰"""
    param1: str = Field(description="å‚æ•°1çš„æè¿°")
    param2: int = Field(default=10, description="å‚æ•°2çš„æè¿°")

@builder.post_tool("agent_role_name")  # â† ä½¿ç”¨ Agent çš„ role_name
@tool(args_schema=MyToolInput)
def my_post_tool(param1: str, param2: int = 10):
    """
    åç½®å·¥å…·å‡½æ•°
    
    è¿™ä¸ªå·¥å…·çš„æè¿°ä¼šè¢« LLM çœ‹åˆ°ï¼Œç”¨äºå†³å®šæ˜¯å¦è°ƒç”¨æ­¤å·¥å…·ã€‚
    
    Args:
        param1: å‚æ•°1
        param2: å‚æ•°2
        
    Returns:
        å·¥å…·æ‰§è¡Œç»“æœ
    """
    # å·¥å…·é€»è¾‘
    result = f"å¤„ç† {param1}ï¼Œå‚æ•°2={param2}"
    return result
```

#### ç¤ºä¾‹ï¼šæ–‡ä»¶è¯»å–å·¥å…·

```python
from pydantic import BaseModel, Field
from langchain.tools import tool
from pathlib import Path

class ReadFileInput(BaseModel):
    file_path: str = Field(description="è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„")

@builder.post_tool("file_processor")
@tool(args_schema=ReadFileInput)
def read_file_tool(file_path: str):
    """è¯»å–æŒ‡å®šæ–‡ä»¶çš„å†…å®¹"""
    try:
        content = Path(file_path).read_text(encoding="utf-8")
        return {"success": True, "content": content}
    except Exception as e:
        return {"success": False, "error": str(e)}
```

### 6.3 å·¥å…·ä½¿ç”¨æµç¨‹

```
1. å®šä¹‰å‰ç½®å·¥å…· (@builder.pre_tool)
   â†“
2. å‰ç½®å·¥å…·æ‰§è¡Œï¼Œæ”¶é›†ä¸Šä¸‹æ–‡
   â†“
3. ä¸Šä¸‹æ–‡æ³¨å…¥åˆ° Prompt
   â†“
4. Agent è°ƒç”¨ LLM
   â†“
5. LLM å†³å®šæ˜¯å¦è°ƒç”¨åç½®å·¥å…·
   â†“
6. æ‰§è¡Œåç½®å·¥å…·ï¼ˆå¦‚æœéœ€è¦ï¼‰
   â†“
7. è¿”å›æœ€ç»ˆç»“æœ
```

---

## 7. èŠ‚ç‚¹ç¼–å†™

### 7.1 èŠ‚ç‚¹å‡½æ•°ç­¾å

èŠ‚ç‚¹å‡½æ•°å¿…é¡»æ˜¯å¼‚æ­¥å‡½æ•°ï¼Œæ¥æ”¶ State å¹¶è¿”å› Stateï¼š

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    """
    èŠ‚ç‚¹å‡½æ•°
    
    Args:
        state: å½“å‰çŠ¶æ€å¯¹è±¡
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€å¯¹è±¡
    """
    # èŠ‚ç‚¹é€»è¾‘
    return state
```

### 7.2 è°ƒç”¨ Agent çš„èŠ‚ç‚¹

```python
async def process_node(state: MyWorkflowState) -> MyWorkflowState:
    """è°ƒç”¨ Agent å¤„ç†æ•°æ®"""
    from dataflow_agent.agentroles import create_simple_agent
    
    # åˆ›å»º Agent
    agent = create_simple_agent(
        name="processor",
        model_name="gpt-4o",
        temperature=0.5,
    )
    
    # æ‰§è¡Œ Agent
    state = await agent.execute(state)
    
    # è·å–ç»“æœ
    result = state.agent_results.get("processor", {}).get("results", {})
    log.info(f"å¤„ç†ç»“æœ: {result}")
    
    return state
```

### 7.3 æ•°æ®å¤„ç†èŠ‚ç‚¹

```python
async def transform_node(state: MyWorkflowState) -> MyWorkflowState:
    """æ•°æ®è½¬æ¢èŠ‚ç‚¹"""
    # ä»å‰ä¸€ä¸ªèŠ‚ç‚¹è·å–ç»“æœ
    previous_result = state.agent_results.get("processor", {}).get("results", {})
    
    # è¿›è¡Œæ•°æ®è½¬æ¢
    transformed = {
        "data": previous_result.get("raw_data", []),
        "metadata": {
            "timestamp": datetime.now().isoformat(),
            "source": "processor"
        }
    }
    
    # å­˜å‚¨åˆ° temp_data
    state.temp_data["transformed_data"] = transformed
    
    return state
```

### 7.4 æ¡ä»¶åˆ¤æ–­èŠ‚ç‚¹

```python
def decision_node(state: MyWorkflowState) -> str:
    """
    æ¡ä»¶åˆ¤æ–­èŠ‚ç‚¹ï¼ˆè¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°ï¼‰
    
    æ³¨æ„ï¼šæ¡ä»¶èŠ‚ç‚¹é€šå¸¸æ˜¯åŒæ­¥å‡½æ•°ï¼Œè¿”å›å­—ç¬¦ä¸²
    """
    result = state.agent_results.get("processor", {}).get("results", {})
    
    if result.get("success"):
        return "success_node"
    else:
        return "error_node"
```

### 7.5 ç»ˆæ­¢èŠ‚ç‚¹

```python
async def end_node(state: MyWorkflowState) -> MyWorkflowState:
    """ç»ˆæ­¢èŠ‚ç‚¹"""
    log.info("Workflow æ‰§è¡Œå®Œæˆ")
    return state

# æˆ–è€…ä½¿ç”¨ lambda
nodes = {
    "_end_": lambda state: state,
}
```

---

## 8. å›¾æ„å»º

### 8.1 æ·»åŠ èŠ‚ç‚¹

```python
# æ–¹å¼ 1: ä½¿ç”¨å­—å…¸æ‰¹é‡æ·»åŠ 
nodes = {
    "step1": step1_node,
    "step2": step2_node,
    "step3": step3_node,
    "_end_": lambda state: state,
}
builder.add_nodes(nodes)

# æ–¹å¼ 2: å•ä¸ªæ·»åŠ 
builder.add_node("step1", step1_node)
builder.add_node("step2", step2_node)
```

### 8.2 æ·»åŠ è¾¹ï¼ˆæ™®é€šè¾¹ï¼‰

```python
# æ–¹å¼ 1: ä½¿ç”¨åˆ—è¡¨æ‰¹é‡æ·»åŠ 
edges = [
    ("step1", "step2"),
    ("step2", "step3"),
    ("step3", "_end_"),
]
builder.add_edges(edges)

# æ–¹å¼ 2: å•ä¸ªæ·»åŠ 
builder.add_edge("step1", "step2")
builder.add_edge("step2", "step3")
```

### 8.3 æ·»åŠ æ¡ä»¶è¾¹

æ¡ä»¶è¾¹æ ¹æ®å‡½æ•°è¿”å›å€¼å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼š

```python
def condition_func(state: MyWorkflowState) -> str:
    """
    æ¡ä»¶å‡½æ•°
    
    Returns:
        ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°
    """
    if state.temp_data.get("success"):
        return "success_node"
    elif state.temp_data.get("retry_count", 0) < 3:
        return "retry_node"
    else:
        return "_end_"

# æ·»åŠ æ¡ä»¶è¾¹
builder.add_conditional_edges({
    "decision_node": condition_func
})
```

### 8.4 é“¾å¼è°ƒç”¨

GenericGraphBuilder æ”¯æŒé“¾å¼è°ƒç”¨ï¼š

```python
builder = (GenericGraphBuilder(state_model=MyWorkflowState, entry_point="start")
    .add_nodes(nodes)
    .add_edges(edges)
    .add_conditional_edges(conditional_edges)
)
```

### 8.5 å®Œæ•´å›¾æ„å»ºç¤ºä¾‹

```python
@register("my_workflow")
def create_my_workflow_graph() -> GenericGraphBuilder:
    builder = GenericGraphBuilder(
        state_model=MyWorkflowState,
        entry_point="start"
    )
    
    # å®šä¹‰èŠ‚ç‚¹
    nodes = {
        "start": start_node,
        "process": process_node,
        "decision": decision_node,
        "success": success_node,
        "retry": retry_node,
        "_end_": lambda state: state,
    }
    
    # å®šä¹‰æ™®é€šè¾¹
    edges = [
        ("start", "process"),
        ("process", "decision"),
        ("success", "_end_"),
        ("retry", "process"),
    ]
    
    # å®šä¹‰æ¡ä»¶è¾¹
    def decision_condition(state: MyWorkflowState) -> str:
        if state.temp_data.get("success"):
            return "success"
        elif state.temp_data.get("retry_count", 0) < 3:
            return "retry"
        else:
            return "_end_"
    
    conditional_edges = {
        "decision": decision_condition
    }
    
    # æ„å»ºå›¾
    return (builder
        .add_nodes(nodes)
        .add_edges(edges)
        .add_conditional_edges(conditional_edges)
    )
```

---

## 9. å®Œæ•´ç¤ºä¾‹

### 9.1 åœºæ™¯ï¼šæ–‡æœ¬åˆ†æ Workflow

åˆ›å»ºä¸€ä¸ªåˆ†ææ–‡æœ¬æƒ…æ„Ÿå’Œå…³é”®è¯çš„ Workflowã€‚

#### Step 1: åˆ›å»º State å’Œ Request

```python
# dataflow_agent/states/text_analysis_state.py
from dataclasses import dataclass, field
from dataflow_agent.state import MainState, MainRequest

@dataclass
class TextAnalysisRequest(MainRequest):
    """æ–‡æœ¬åˆ†æè¯·æ±‚"""
    text: str = ""
    analysis_type: str = "sentiment"  # "sentiment" | "keywords" | "both"

@dataclass
class TextAnalysisState(MainState):
    """æ–‡æœ¬åˆ†æçŠ¶æ€"""
    request: TextAnalysisRequest = field(default_factory=TextAnalysisRequest)
    
    # åˆ†æç»“æœ
    sentiment_result: dict = field(default_factory=dict)
    keywords_result: dict = field(default_factory=dict)
    final_report: str = ""
```

#### Step 2: åˆ›å»º Workflow

```python
# dataflow_agent/workflow/wf_text_analysis.py
"""
text_analysis workflow
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
åŠŸèƒ½ï¼šåˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå’Œå…³é”®è¯
"""

from __future__ import annotations
from dataflow_agent.states.text_analysis_state import TextAnalysisState
from dataflow_agent.graphbuilder.graph_builder import GenericGraphBuilder
from dataflow_agent.workflow.registry import register
from dataflow_agent.agentroles import create_simple_agent
from dataflow_agent.logger import get_logger

log = get_logger(__name__)

@register("text_analysis")
def create_text_analysis_graph() -> GenericGraphBuilder:
    """åˆ›å»ºæ–‡æœ¬åˆ†æå·¥ä½œæµ"""
    builder = GenericGraphBuilder(
        state_model=TextAnalysisState,
        entry_point="start"
    )
    
    # ========== å‰ç½®å·¥å…· ==========
    @builder.pre_tool("text", "sentiment_analysis")
    def get_text_for_sentiment(state: TextAnalysisState):
        return state.request.text
    
    @builder.pre_tool("text", "keyword_extraction")
    def get_text_for_keywords(state: TextAnalysisState):
        return state.request.text
    
    @builder.pre_tool("sentiment", "report_generation")
    def get_sentiment(state: TextAnalysisState):
        return state.sentiment_result
    
    @builder.pre_tool("keywords", "report_generation")
    def get_keywords(state: TextAnalysisState):
        return state.keywords_result
    
    # ========== èŠ‚ç‚¹å®šä¹‰ ==========
    async def start_node(state: TextAnalysisState) -> TextAnalysisState:
        """èµ·å§‹èŠ‚ç‚¹"""
        log.info(f"å¼€å§‹åˆ†ææ–‡æœ¬ï¼Œç±»å‹: {state.request.analysis_type}")
        return state
    
    async def sentiment_analysis_node(state: TextAnalysisState) -> TextAnalysisState:
        """æƒ…æ„Ÿåˆ†æèŠ‚ç‚¹"""
        agent = create_simple_agent(
            name="sentiment_analyzer",
            model_name="gpt-4o",
            temperature=0.3,
            parser_type="json",
        )
        
        state = await agent.execute(state)
        
        # ä¿å­˜ç»“æœ
        result = state.agent_results.get("sentiment_analyzer", {}).get("results", {})
        state.sentiment_result = result
        
        log.info(f"æƒ…æ„Ÿåˆ†æå®Œæˆ: {result}")
        return state
    
    async def keyword_extraction_node(state: TextAnalysisState) -> TextAnalysisState:
        """å…³é”®è¯æå–èŠ‚ç‚¹"""
        agent = create_simple_agent(
            name="keyword_extractor",
            model_name="gpt-4o",
            temperature=0.3,
            parser_type="json",
        )
        
        state = await agent.execute(state)
        
        # ä¿å­˜ç»“æœ
        result = state.agent_results.get("keyword_extractor", {}).get("results", {})
        state.keywords_result = result
        
        log.info(f"å…³é”®è¯æå–å®Œæˆ: {result}")
        return state
    
    async def report_generation_node(state: TextAnalysisState) -> TextAnalysisState:
        """æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹"""
        agent = create_simple_agent(
            name="report_generator",
            model_name="gpt-4o",
            temperature=0.7,
            parser_type="text",
        )
        
        state = await agent.execute(state)
        
        # ä¿å­˜æŠ¥å‘Š
        result = state.agent_results.get("report_generator", {}).get("results", {})
        state.final_report = result.get("raw", "")
        
        log.info("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return state
    
    # ========== æ¡ä»¶åˆ¤æ–­ ==========
    def route_after_start(state: TextAnalysisState) -> str:
        """æ ¹æ®åˆ†æç±»å‹è·¯ç”±"""
        analysis_type = state.request.analysis_type
        
        if analysis_type == "sentiment":
            return "sentiment_analysis"
        elif analysis_type == "keywords":
            return "keyword_extraction"
        else:  # "both"
            return "sentiment_analysis"
    
    def route_after_sentiment(state: TextAnalysisState) -> str:
        """æƒ…æ„Ÿåˆ†æåçš„è·¯ç”±"""
        if state.request.analysis_type == "both":
            return "keyword_extraction"
        else:
            return "report_generation"
    
    # ========== å›¾æ„å»º ==========
    nodes = {
        "start": start_node,
        "sentiment_analysis": sentiment_analysis_node,
        "keyword_extraction": keyword_extraction_node,
        "report_generation": report_generation_node,
        "_end_": lambda state: state,
    }
    
    edges = [
        ("keyword_extraction", "report_generation"),
        ("report_generation", "_end_"),
    ]
    
    conditional_edges = {
        "start": route_after_start,
        "sentiment_analysis": route_after_sentiment,
    }
    
    return (builder
        .add_nodes(nodes)
        .add_edges(edges)
        .add_conditional_edges(conditional_edges)
    )
```

#### Step 3: åˆ›å»ºæµ‹è¯•æ–‡ä»¶

```python
# tests/test_text_analysis.py
"""
æµ‹è¯• text_analysis workflow
"""

import asyncio
import pytest
from dataflow_agent.states.text_analysis_state import TextAnalysisState, TextAnalysisRequest
from dataflow_agent.workflow import run_workflow

async def run_text_analysis_pipeline():
    """æ‰§è¡Œæ–‡æœ¬åˆ†æå·¥ä½œæµ"""
    # æ„é€ è¯·æ±‚
    request = TextAnalysisRequest(
        text="è¿™æ˜¯ä¸€ä¸ªéå¸¸æ£’çš„äº§å“ï¼Œæˆ‘å¾ˆå–œæ¬¢ï¼",
        analysis_type="both",
        language="zh",
        model="gpt-4o",
    )
    
    # åˆå§‹åŒ–çŠ¶æ€
    state = TextAnalysisState(request=request)
    
    # è¿è¡Œ workflow
    final_state = await run_workflow("text_analysis", state)
    
    return final_state

@pytest.mark.asyncio
async def test_text_analysis_pipeline():
    """æµ‹è¯•æ–‡æœ¬åˆ†æå·¥ä½œæµ"""
    final_state = await run_text_analysis_pipeline()
    
    # æ–­è¨€
    assert final_state is not None
    assert final_state.sentiment_result
    assert final_state.keywords_result
    assert final_state.final_report
    
    # æ‰“å°ç»“æœ
    print("\n=== æƒ…æ„Ÿåˆ†æç»“æœ ===")
    print(final_state.sentiment_result)
    
    print("\n=== å…³é”®è¯æå–ç»“æœ ===")
    print(final_state.keywords_result)
    
    print("\n=== æœ€ç»ˆæŠ¥å‘Š ===")
    print(final_state.final_report)

if __name__ == "__main__":
    asyncio.run(run_text_analysis_pipeline())
```

### 9.2 åœºæ™¯ï¼šæ‰¹é‡æ•°æ®å¤„ç† Workflowï¼ˆå¹¶è¡Œæ¨¡å¼ï¼‰

åˆ›å»ºä¸€ä¸ªæ‰¹é‡å¤„ç†å¤šæ¡æ•°æ®çš„ Workflowï¼Œå±•ç¤ºå¹¶è¡Œæ¨¡å¼çš„ä½¿ç”¨ã€‚

#### Step 1: åˆ›å»º State å’Œ Request

```python
# dataflow_agent/states/batch_process_state.py
from dataclasses import dataclass, field
from typing import List
from dataflow_agent.state import MainState, MainRequest

@dataclass
class BatchProcessRequest(MainRequest):
    """æ‰¹é‡å¤„ç†è¯·æ±‚"""
    items: List[dict] = field(default_factory=list)  # å¾…å¤„ç†çš„æ•°æ®åˆ—è¡¨
    process_type: str = "summarize"  # å¤„ç†ç±»å‹

@dataclass
class BatchProcessState(MainState):
    """æ‰¹é‡å¤„ç†çŠ¶æ€"""
    request: BatchProcessRequest = field(default_factory=BatchProcessRequest)
    
    # å¤„ç†ç»“æœ
    processed_items: List[dict] = field(default_factory=list)
    success_count: int = 0
    error_count: int = 0
    summary: str = ""
```

#### Step 2: åˆ›å»º Workflow

```python
# dataflow_agent/workflow/wf_batch_process.py
"""
batch_process workflow
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
åŠŸèƒ½ï¼šæ‰¹é‡å¤„ç†å¤šæ¡æ•°æ®ï¼Œä½¿ç”¨å¹¶è¡Œæ¨¡å¼æé«˜æ•ˆç‡
"""

from __future__ import annotations
from dataflow_agent.states.batch_process_state import BatchProcessState
from dataflow_agent.graphbuilder.graph_builder import GenericGraphBuilder
from dataflow_agent.workflow.registry import register
from dataflow_agent.agentroles import create_parallel_agent, create_simple_agent
from dataflow_agent.logger import get_logger

log = get_logger(__name__)

@register("batch_process")
def create_batch_process_graph() -> GenericGraphBuilder:
    """åˆ›å»ºæ‰¹é‡å¤„ç†å·¥ä½œæµ"""
    builder = GenericGraphBuilder(
        state_model=BatchProcessState,
        entry_point="prepare"
    )
    
    # ========== å‰ç½®å·¥å…· ==========
    
    # ä¸ºå¹¶è¡Œå¤„ç† Agent å‡†å¤‡æ•°æ®
    @builder.pre_tool("items", "batch_processor")
    def get_items_for_parallel(state: BatchProcessState):
        """è¿”å›éœ€è¦å¹¶è¡Œå¤„ç†çš„æ•°æ®åˆ—è¡¨"""
        # å°†æ¯ä¸ª item åŒ…è£…æˆåŒ…å«å¿…è¦ä¸Šä¸‹æ–‡çš„å­—å…¸
        return [
            {
                "item": item,
                "process_type": state.request.process_type,
                "index": idx
            }
            for idx, item in enumerate(state.request.items)
        ]
    
    # ä¸ºæ±‡æ€» Agent å‡†å¤‡æ•°æ®
    @builder.pre_tool("results", "summarizer")
    def get_results_for_summary(state: BatchProcessState):
        return state.processed_items
    
    @builder.pre_tool("stats", "summarizer")
    def get_stats_for_summary(state: BatchProcessState):
        return {
            "total": len(state.request.items),
            "success": state.success_count,
            "error": state.error_count
        }
    
    # ========== èŠ‚ç‚¹å®šä¹‰ ==========
    
    async def prepare_node(state: BatchProcessState) -> BatchProcessState:
        """å‡†å¤‡èŠ‚ç‚¹ï¼šéªŒè¯è¾“å…¥æ•°æ®"""
        items = state.request.items
        
        if not items:
            log.warning("æ²¡æœ‰å¾…å¤„ç†çš„æ•°æ®")
            state.temp_data["skip_processing"] = True
        else:
            log.info(f"å‡†å¤‡å¤„ç† {len(items)} æ¡æ•°æ®")
            state.temp_data["skip_processing"] = False
        
        return state
    
    async def parallel_process_node(state: BatchProcessState) -> BatchProcessState:
        """å¹¶è¡Œå¤„ç†èŠ‚ç‚¹ï¼šä½¿ç”¨å¹¶è¡Œæ¨¡å¼å¤„ç†æ‰€æœ‰æ•°æ®"""
        
        # åˆ›å»ºå¹¶è¡Œæ¨¡å¼ Agent
        agent = create_parallel_agent(
            name="batch_processor",
            model_name="gpt-4o",
            temperature=0.3,
            concurrency_limit=5,  # åŒæ—¶å¤„ç†5æ¡æ•°æ®
            parser_type="json",
        )
        
        # æ‰§è¡Œå¹¶è¡Œå¤„ç†
        state = await agent.execute(state)
        
        # æå–å¹¶è¡Œç»“æœ
        result = state.agent_results.get("batch_processor", {}).get("results", {})
        parallel_results = result.get("parallel_results", [])
        
        # ç»Ÿè®¡ç»“æœ
        success_count = 0
        error_count = 0
        processed_items = []
        
        for idx, item_result in enumerate(parallel_results):
            if item_result.get("error"):
                error_count += 1
                processed_items.append({
                    "index": idx,
                    "status": "error",
                    "error": item_result.get("error")
                })
            else:
                success_count += 1
                processed_items.append({
                    "index": idx,
                    "status": "success",
                    "result": item_result
                })
        
        # æ›´æ–°çŠ¶æ€
        state.processed_items = processed_items
        state.success_count = success_count
        state.error_count = error_count
        
        log.info(f"å¹¶è¡Œå¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {error_count}")
        return state
    
    async def summarize_node(state: BatchProcessState) -> BatchProcessState:
        """æ±‡æ€»èŠ‚ç‚¹ï¼šç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        
        agent = create_simple_agent(
            name="summarizer",
            model_name="gpt-4o",
            temperature=0.5,
            parser_type="text",
        )
        
        state = await agent.execute(state)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        result = state.agent_results.get("summarizer", {}).get("results", {})
        state.summary = result.get("raw", "")
        
        log.info("æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return state
    
    # ========== æ¡ä»¶åˆ¤æ–­ ==========
    
    def check_skip(state: BatchProcessState) -> str:
        """æ£€æŸ¥æ˜¯å¦è·³è¿‡å¤„ç†"""
        if state.temp_data.get("skip_processing"):
            return "_end_"
        return "parallel_process"
    
    # ========== å›¾æ„å»º ==========
    
    nodes = {
        "prepare": prepare_node,
        "parallel_process": parallel_process_node,
        "summarize": summarize_node,
        "_end_": lambda state: state,
    }
    
    edges = [
        ("parallel_process", "summarize"),
        ("summarize", "_end_"),
    ]
    
    conditional_edges = {
        "prepare": check_skip,
    }
    
    return (builder
        .add_nodes(nodes)
        .add_edges(edges)
        .add_conditional_edges(conditional_edges)
    )
```

#### Step 3: åˆ›å»ºæµ‹è¯•æ–‡ä»¶

```python
# tests/test_batch_process.py
"""
æµ‹è¯• batch_process workflow
"""

import asyncio
import pytest
from dataflow_agent.states.batch_process_state import BatchProcessState, BatchProcessRequest
from dataflow_agent.workflow import run_workflow

async def run_batch_process_pipeline():
    """æ‰§è¡Œæ‰¹é‡å¤„ç†å·¥ä½œæµ"""
    # æ„é€ è¯·æ±‚
    request = BatchProcessRequest(
        items=[
            {"title": "æ–‡ç« 1", "content": "è¿™æ˜¯ç¬¬ä¸€ç¯‡æ–‡ç« çš„å†…å®¹..."},
            {"title": "æ–‡ç« 2", "content": "è¿™æ˜¯ç¬¬äºŒç¯‡æ–‡ç« çš„å†…å®¹..."},
            {"title": "æ–‡ç« 3", "content": "è¿™æ˜¯ç¬¬ä¸‰ç¯‡æ–‡ç« çš„å†…å®¹..."},
            {"title": "æ–‡ç« 4", "content": "è¿™æ˜¯ç¬¬å››ç¯‡æ–‡ç« çš„å†…å®¹..."},
            {"title": "æ–‡ç« 5", "content": "è¿™æ˜¯ç¬¬äº”ç¯‡æ–‡ç« çš„å†…å®¹..."},
        ],
        process_type="summarize",
        language="zh",
        model="gpt-4o",
    )
    
    # åˆå§‹åŒ–çŠ¶æ€
    state = BatchProcessState(request=request)
    
    # è¿è¡Œ workflow
    final_state = await run_workflow("batch_process", state)
    
    return final_state

@pytest.mark.asyncio
async def test_batch_process_pipeline():
    """æµ‹è¯•æ‰¹é‡å¤„ç†å·¥ä½œæµ"""
    final_state = await run_batch_process_pipeline()
    
    # æ–­è¨€
    assert final_state is not None
    assert len(final_state.processed_items) == 5
    assert final_state.success_count + final_state.error_count == 5
    
    # æ‰“å°ç»“æœ
    print(f"\n=== å¤„ç†ç»Ÿè®¡ ===")
    print(f"æˆåŠŸ: {final_state.success_count}")
    print(f"å¤±è´¥: {final_state.error_count}")
    
    print(f"\n=== å¤„ç†è¯¦æƒ… ===")
    for item in final_state.processed_items:
        print(f"  [{item['index']}] {item['status']}")
    
    print(f"\n=== æ±‡æ€»æŠ¥å‘Š ===")
    print(final_state.summary)

if __name__ == "__main__":
    asyncio.run(run_batch_process_pipeline())
```

---

## 10. è°ƒè¯•å’Œæµ‹è¯•

### 10.1 æ·»åŠ æ—¥å¿—

```python
from dataflow_agent.logger import get_logger

log = get_logger(__name__)

async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    log.info("å¼€å§‹å¤„ç†èŠ‚ç‚¹")
    log.debug(f"å½“å‰çŠ¶æ€: {state}")
    
    try:
        # å¤„ç†é€»è¾‘
        result = await process_data(state)
        log.info(f"å¤„ç†æˆåŠŸ: {result}")
    except Exception as e:
        log.error(f"å¤„ç†å¤±è´¥: {e}")
        log.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯")
    
    return state
```

### 10.2 è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œå•ä¸ªæµ‹è¯•æ–‡ä»¶
pytest tests/test_my_workflow.py -v -s

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ -v

# ç›´æ¥è¿è¡Œæµ‹è¯•æ–‡ä»¶
python tests/test_my_workflow.py
```

### 10.3 è°ƒè¯•æŠ€å·§

#### 1. æ‰“å°ä¸­é—´çŠ¶æ€

```python
async def debug_node(state: MyWorkflowState) -> MyWorkflowState:
    """è°ƒè¯•èŠ‚ç‚¹"""
    log.critical("=== è°ƒè¯•ä¿¡æ¯ ===")
    log.critical(f"Request: {state.request}")
    log.critical(f"Agent Results: {state.agent_results}")
    log.critical(f"Temp Data: {state.temp_data}")
    return state
```

#### 2. æ£€æŸ¥ Agent ç»“æœ

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    state = await agent.execute(state)
    
    # æ£€æŸ¥ç»“æœ
    result = state.agent_results.get("my_agent", {})
    log.info(f"å‰ç½®å·¥å…·ç»“æœ: {result.get('pre_tool_results')}")
    log.info(f"åç½®å·¥å…·: {result.get('post_tools')}")
    log.info(f"æ‰§è¡Œç»“æœ: {result.get('results')}")
    
    return state
```

#### 3. ä½¿ç”¨æ–­ç‚¹

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    # åœ¨éœ€è¦çš„åœ°æ–¹æ·»åŠ æ–­ç‚¹
    import pdb; pdb.set_trace()
    
    # æˆ–ä½¿ç”¨ breakpoint()ï¼ˆPython 3.7+ï¼‰
    breakpoint()
    
    return state
```

### 10.4 å¸¸è§é—®é¢˜æ’æŸ¥

#### é—®é¢˜ 1: Agent æœªæ³¨å†Œ

```
é”™è¯¯: KeyError: 'my_agent'
è§£å†³: ç¡®ä¿ Agent ç±»ä½¿ç”¨äº† @register è£…é¥°å™¨æˆ–æ­£ç¡®ç»§æ‰¿äº† BaseAgent
```

#### é—®é¢˜ 2: å‰ç½®å·¥å…·æœªæ‰§è¡Œ

```
é”™è¯¯: å‰ç½®å·¥å…·ç»“æœä¸ºç©º
è§£å†³: æ£€æŸ¥ @builder.pre_tool çš„ç¬¬äºŒä¸ªå‚æ•°æ˜¯å¦ä¸ Agent çš„ role_name åŒ¹é…ï¼ˆä¸æ˜¯èŠ‚ç‚¹åç§°ï¼ï¼‰
```

#### é—®é¢˜ 3: State å­—æ®µç¼ºå¤±

```
é”™è¯¯: AttributeError: 'MyWorkflowState' object has no attribute 'xxx'
è§£å†³: åœ¨ State ç±»ä¸­æ·»åŠ ç¼ºå¤±çš„å­—æ®µå®šä¹‰
```

#### é—®é¢˜ 4: å·¥å…·ç»‘å®šåˆ°é”™è¯¯çš„è§’è‰²

```
é”™è¯¯: Agent æ‰§è¡Œæ—¶è·å–ä¸åˆ°å‰ç½®å·¥å…·ç»“æœ
åŸå› : @builder.pre_tool("xxx", "node_name") ä½¿ç”¨äº†èŠ‚ç‚¹åç§°è€Œä¸æ˜¯ Agent çš„ role_name
è§£å†³: å°†ç¬¬äºŒä¸ªå‚æ•°æ”¹ä¸º Agent çš„ role_name
ç¤ºä¾‹: @builder.pre_tool("xxx", "my_agent")  # my_agent æ˜¯ Agent çš„ role_name
```

---

## 11. æœ€ä½³å®è·µ

### 11.1 æ¨¡å—åŒ–è®¾è®¡

**åŸåˆ™**: æ¯ä¸ªèŠ‚ç‚¹åŠŸèƒ½å•ä¸€æ˜ç¡®

```python
# âœ… å¥½çš„åšæ³•
async def fetch_data_node(state):
    """åªè´Ÿè´£è·å–æ•°æ®"""
    state.raw_data = await fetch_from_api()
    return state

async def process_data_node(state):
    """åªè´Ÿè´£å¤„ç†æ•°æ®"""
    state.processed_data = process(state.raw_data)
    return state

# âŒ ä¸å¥½çš„åšæ³•
async def fetch_and_process_node(state):
    """ä¸€ä¸ªèŠ‚ç‚¹åšå¤ªå¤šäº‹æƒ…"""
    state.raw_data = await fetch_from_api()
    state.processed_data = process(state.raw_data)
    state.validated_data = validate(state.processed_data)
    state.final_result = transform(state.validated_data)
    return state
```

### 11.2 é”™è¯¯å¤„ç†

**åŸåˆ™**: åœ¨èŠ‚ç‚¹ä¸­æ·»åŠ å¼‚å¸¸æ•è·

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    """å¸¦é”™è¯¯å¤„ç†çš„èŠ‚ç‚¹"""
    try:
        # ä¸»è¦é€»è¾‘
        result = await agent.execute(state)
        state.success = True
        return result
    except Exception as e:
        log.exception(f"èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {e}")
        
        # è®°å½•é”™è¯¯
        state.temp_data["error"] = str(e)
        state.success = False
        
        # å¯ä»¥é€‰æ‹©ç»§ç»­æˆ–ç»ˆæ­¢
        return state
```

### 11.3 çŠ¶æ€ç®¡ç†

**åŸåˆ™**: åˆç†è®¾è®¡ State ç±»çš„å­—æ®µ

```python
# âœ… å¥½çš„åšæ³•ï¼šæ¸…æ™°çš„å­—æ®µåˆ†ç±»
@dataclass
class MyWorkflowState(MainState):
    # è¾“å…¥æ•°æ®
    request: MyWorkflowRequest = field(default_factory=MyWorkflowRequest)
    
    # ä¸­é—´ç»“æœ
    intermediate_data: dict = field(default_factory=dict)
    processing_status: str = "pending"
    
    # æœ€ç»ˆè¾“å‡º
    final_result: dict = field(default_factory=dict)
    
    # å…ƒæ•°æ®
    start_time: str = ""
    end_time: str = ""
    duration: float = 0.0

# âŒ ä¸å¥½çš„åšæ³•ï¼šå­—æ®µæ··ä¹±
@dataclass
class MyWorkflowState(MainState):
    data1: dict = field(default_factory=dict)
    data2: dict = field(default_factory=dict)
    result: dict = field(default_factory=dict)
    temp: dict = field(default_factory=dict)
```

### 11.4 å·¥å…·å¤ç”¨

**åŸåˆ™**: å……åˆ†åˆ©ç”¨ç°æœ‰çš„å·¥å…·å‡½æ•°

```python
# å¤ç”¨é¡¹ç›®ä¸­çš„å·¥å…·
from dataflow_agent.toolkits.basetool.file_tools import local_tool_for_sample
from dataflow_agent.toolkits.optool.op_tools import get_operator_content_str

@builder.pre_tool("sample_data", "my_node")
def get_sample(state: MyWorkflowState):
    """å¤ç”¨ç°æœ‰å·¥å…·"""
    from types import SimpleNamespace
    req = SimpleNamespace(json_file=state.request.data_file)
    return local_tool_for_sample(req, sample_size=5)
```

### 11.5 æ–‡æ¡£æ³¨é‡Š

**åŸåˆ™**: ä¸ºæ¯ä¸ªèŠ‚ç‚¹å’Œå·¥å…·æ·»åŠ è¯¦ç»†æ³¨é‡Š

```python
async def my_node(state: MyWorkflowState) -> MyWorkflowState:
    """
    èŠ‚ç‚¹åŠŸèƒ½æè¿°
    
    æ­¤èŠ‚ç‚¹è´Ÿè´£ï¼š
    1. ä» API è·å–æ•°æ®
    2. éªŒè¯æ•°æ®æ ¼å¼
    3. å­˜å‚¨åˆ° state.raw_data
    
    Args:
        state: å½“å‰å·¥ä½œæµçŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€å¯¹è±¡
        
    Raises:
        ValueError: å½“æ•°æ®æ ¼å¼ä¸æ­£ç¡®æ—¶
        ConnectionError: å½“ API è¿æ¥å¤±è´¥æ—¶
    """
    # å®ç°
    pass
```

### 11.6 å¹¶è¡Œæ¨¡å¼æœ€ä½³å®è·µ

**åŸåˆ™**: åˆç†ä½¿ç”¨å¹¶è¡Œæ¨¡å¼æé«˜æ•ˆç‡

#### ä½•æ—¶ä½¿ç”¨å¹¶è¡Œæ¨¡å¼

âœ… **é€‚åˆä½¿ç”¨å¹¶è¡Œæ¨¡å¼çš„åœºæ™¯**ï¼š
- éœ€è¦å¤„ç†å¤šæ¡ç‹¬ç«‹çš„æ•°æ®ï¼ˆå¦‚æ‰¹é‡æ–‡æœ¬åˆ†æã€å›¾åƒå¤„ç†ï¼‰
- æ¯æ¡æ•°æ®çš„å¤„ç†é€»è¾‘ç›¸åŒ
- æ•°æ®ä¹‹é—´æ²¡æœ‰ä¾èµ–å…³ç³»
- å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå¹¶è¡Œå¯ä»¥æ˜¾è‘—æå‡æ•ˆç‡

âŒ **ä¸é€‚åˆä½¿ç”¨å¹¶è¡Œæ¨¡å¼çš„åœºæ™¯**ï¼š
- æ•°æ®ä¹‹é—´æœ‰ä¾èµ–å…³ç³»ï¼ˆéœ€è¦æŒ‰é¡ºåºå¤„ç†ï¼‰
- æ•°æ®é‡å¾ˆå°ï¼ˆå¹¶è¡Œå¼€é”€å¤§äºæ”¶ç›Šï¼‰
- éœ€è¦å…±äº«çŠ¶æ€æˆ–ç´¯ç§¯ç»“æœ
- å¤„ç†é€»è¾‘å¤æ‚ä¸”éœ€è¦å¤§é‡ä¸Šä¸‹æ–‡

#### å¹¶å‘åº¦è®¾ç½®å»ºè®®

```python
# æ ¹æ®ä»»åŠ¡ç‰¹ç‚¹è®¾ç½®åˆé€‚çš„å¹¶å‘åº¦
agent = create_parallel_agent(
    name="processor",
    concurrency_limit=5,  # å»ºè®®å€¼ï¼š3-10
)
```

**è®¾ç½®åŸåˆ™**ï¼š
- **API é™æµè€ƒè™‘**ï¼šå¦‚æœ LLM API æœ‰é€Ÿç‡é™åˆ¶ï¼Œè®¾ç½®è¾ƒä½çš„å¹¶å‘åº¦ï¼ˆ3-5ï¼‰
- **æ•°æ®é‡è€ƒè™‘**ï¼šæ•°æ®é‡å¤§æ—¶å¯ä»¥é€‚å½“æé«˜å¹¶å‘åº¦ï¼ˆ5-10ï¼‰
- **èµ„æºé™åˆ¶**ï¼šè€ƒè™‘å†…å­˜å’Œç½‘ç»œå¸¦å®½ï¼Œé¿å…è¿‡é«˜å¹¶å‘å¯¼è‡´ç³»ç»Ÿè´Ÿè½½è¿‡å¤§
- **æˆæœ¬æ§åˆ¶**ï¼šå¹¶å‘åº¦è¶Šé«˜ï¼ŒAPI è°ƒç”¨æˆæœ¬è¶Šé«˜

#### æ•°æ®å‡†å¤‡æ³¨æ„äº‹é¡¹

```python
# âœ… å¥½çš„åšæ³•ï¼šä¸ºæ¯ä¸ªå¹¶è¡Œé¡¹æä¾›å®Œæ•´ä¸Šä¸‹æ–‡
@builder.pre_tool("items", "batch_processor")
def prepare_parallel_data(state: MyWorkflowState):
    return [
        {
            "item": item,
            "context": state.request.context,  # å…±äº«ä¸Šä¸‹æ–‡
            "config": state.request.config,    # å…±äº«é…ç½®
            "index": idx                       # ç”¨äºè¿½è¸ª
        }
        for idx, item in enumerate(state.request.items)
    ]

# âŒ ä¸å¥½çš„åšæ³•ï¼šåªä¼ é€’åŸå§‹æ•°æ®
@builder.pre_tool("items", "batch_processor")
def prepare_parallel_data(state: MyWorkflowState):
    return state.request.items  # ç¼ºå°‘å¿…è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
```

#### é”™è¯¯å¤„ç†å»ºè®®

```python
async def parallel_process_node(state: MyWorkflowState) -> MyWorkflowState:
    """å¹¶è¡Œå¤„ç†èŠ‚ç‚¹ï¼ˆå¸¦å®Œå–„çš„é”™è¯¯å¤„ç†ï¼‰"""
    
    agent = create_parallel_agent(
        name="batch_processor",
        concurrency_limit=5,
    )
    
    state = await agent.execute(state)
    
    # æå–ç»“æœ
    result = state.agent_results.get("batch_processor", {}).get("results", {})
    parallel_results = result.get("parallel_results", [])
    
    # åˆ†ç±»å¤„ç†ç»“æœ
    success_items = []
    failed_items = []
    
    for idx, item_result in enumerate(parallel_results):
        if item_result.get("error"):
            # è®°å½•å¤±è´¥é¡¹
            failed_items.append({
                "index": idx,
                "error": item_result.get("error"),
                "original_data": state.request.items[idx]
            })
            log.warning(f"é¡¹ {idx} å¤„ç†å¤±è´¥: {item_result.get('error')}")
        else:
            success_items.append({
                "index": idx,
                "result": item_result
            })
    
    # ä¿å­˜ç»“æœ
    state.temp_data["success_items"] = success_items
    state.temp_data["failed_items"] = failed_items
    
    # å†³å®šæ˜¯å¦éœ€è¦é‡è¯•å¤±è´¥é¡¹
    if failed_items and len(failed_items) < len(parallel_results) * 0.3:
        # å¦‚æœå¤±è´¥ç‡ä½äº30%ï¼Œå¯ä»¥è€ƒè™‘é‡è¯•
        log.info(f"å°†é‡è¯• {len(failed_items)} ä¸ªå¤±è´¥é¡¹")
        state.temp_data["need_retry"] = True
    else:
        state.temp_data["need_retry"] = False
    
    return state
```

#### ç»“æœèšåˆæ¨¡å¼

```python
async def aggregate_results_node(state: MyWorkflowState) -> MyWorkflowState:
    """èšåˆå¹¶è¡Œå¤„ç†ç»“æœ"""
    
    success_items = state.temp_data.get("success_items", [])
    failed_items = state.temp_data.get("failed_items", [])
    
    # æ¨¡å¼ 1: ç»Ÿè®¡èšåˆ
    stats = {
        "total": len(success_items) + len(failed_items),
        "success": len(success_items),
        "failed": len(failed_items),
        "success_rate": len(success_items) / (len(success_items) + len(failed_items))
    }
    
    # æ¨¡å¼ 2: æ•°æ®èšåˆ
    aggregated_data = {
        "all_results": [item["result"] for item in success_items],
        "summary": {
            "key_metrics": calculate_metrics(success_items),
            "common_patterns": find_patterns(success_items)
        }
    }
    
    # æ¨¡å¼ 3: åˆ†ç»„èšåˆ
    grouped_results = {}
    for item in success_items:
        category = item["result"].get("category", "unknown")
        if category not in grouped_results:
            grouped_results[category] = []
        grouped_results[category].append(item)
    
    state.temp_data["aggregated"] = {
        "stats": stats,
        "data": aggregated_data,
        "grouped": grouped_results
    }
    
    return state
```

#### æ€§èƒ½ä¼˜åŒ–å»ºè®®

```python
# 1. ä½¿ç”¨åˆé€‚çš„æ•°æ®ç»“æ„
@builder.pre_tool("items", "batch_processor")
def prepare_data(state: MyWorkflowState):
    # âœ… å¥½ï¼šé¢„å¤„ç†æ•°æ®ï¼Œå‡å°‘æ¯ä¸ªå¹¶è¡Œä»»åŠ¡çš„å·¥ä½œé‡
    return [
        {
            "text": item["text"].strip(),  # é¢„å¤„ç†
            "metadata": extract_metadata(item),  # æå‰æå–
            "index": idx
        }
        for idx, item in enumerate(state.request.items)
    ]

# 2. æ‰¹é‡å¤§å°æ§åˆ¶
def split_into_batches(items: list, batch_size: int = 50):
    """å°†å¤§é‡æ•°æ®åˆ†æ‰¹å¤„ç†"""
    for i in range(0, len(items), batch_size):
        yield items[i:i + batch_size]

async def process_large_dataset(state: MyWorkflowState):
    """å¤„ç†å¤§æ•°æ®é›†"""
    all_results = []
    
    for batch in split_into_batches(state.request.items, batch_size=50):
        # æ¯æ‰¹ä½¿ç”¨å¹¶è¡Œæ¨¡å¼å¤„ç†
        batch_state = create_batch_state(batch)
        result = await process_batch(batch_state)
        all_results.extend(result)
    
    return all_results

# 3. ç›‘æ§å’Œæ—¥å¿—
async def parallel_process_with_monitoring(state: MyWorkflowState):
    """å¸¦ç›‘æ§çš„å¹¶è¡Œå¤„ç†"""
    import time
    
    start_time = time.time()
    
    agent = create_parallel_agent(
        name="batch_processor",
        concurrency_limit=5,
    )
    
    state = await agent.execute(state)
    
    elapsed = time.time() - start_time
    
    # è®°å½•æ€§èƒ½æŒ‡æ ‡
    log.info(f"å¹¶è¡Œå¤„ç†å®Œæˆ:")
    log.info(f"  - æ€»æ•°: {len(state.request.items)}")
    log.info(f"  - è€—æ—¶: {elapsed:.2f}ç§’")
    log.info(f"  - å¹³å‡: {elapsed/len(state.request.items):.2f}ç§’/é¡¹")
    log.info(f"  - åå: {len(state.request.items)/elapsed:.2f}é¡¹/ç§’")
    
    return state
```

#### å¸¸è§é™·é˜±

âŒ **é™·é˜± 1ï¼šå¿½ç•¥å…±äº«çŠ¶æ€**
```python
# é”™è¯¯ï¼šå¹¶è¡Œä»»åŠ¡ä¹‹é—´å…±äº«å¯å˜çŠ¶æ€
shared_counter = {"count": 0}

@builder.pre_tool("items", "processor")
def prepare_data(state):
    return [{"data": item, "counter": shared_counter} for item in items]
    # é—®é¢˜ï¼šå¹¶å‘ä¿®æ”¹ shared_counter ä¼šå¯¼è‡´ç«æ€æ¡ä»¶
```

âœ… **æ­£ç¡®åšæ³•ï¼šæ¯ä¸ªä»»åŠ¡ç‹¬ç«‹**
```python
@builder.pre_tool("items", "processor")
def prepare_data(state):
    return [{"data": item, "index": idx} for idx, item in enumerate(items)]
    # æ¯ä¸ªä»»åŠ¡æœ‰ç‹¬ç«‹çš„ indexï¼Œä¸å…±äº«å¯å˜çŠ¶æ€
```

âŒ **é™·é˜± 2ï¼šè¿‡åº¦å¹¶è¡Œ**
```python
# é”™è¯¯ï¼šå¯¹å°‘é‡æ•°æ®ä½¿ç”¨é«˜å¹¶å‘
agent = create_parallel_agent(
    name="processor",
    concurrency_limit=20,  # åªæœ‰5æ¡æ•°æ®å´è®¾ç½®20å¹¶å‘
)
```

âœ… **æ­£ç¡®åšæ³•ï¼šæ ¹æ®æ•°æ®é‡è°ƒæ•´**
```python
# æ ¹æ®æ•°æ®é‡åŠ¨æ€è°ƒæ•´å¹¶å‘åº¦
data_count = len(state.request.items)
concurrency = min(data_count, 5)  # æœ€å¤š5å¹¶å‘

agent = create_parallel_agent(
    name="processor",
    concurrency_limit=concurrency,
)
```

---

## æ€»ç»“

æœ¬æ•™ç¨‹æ¶µç›–äº† DataFlow-Agent é¡¹ç›®ä¸­ Workflow ç¼–å†™çš„å®Œæ•´æµç¨‹ï¼š

1. âœ… ä½¿ç”¨ CLI å¿«é€Ÿåˆ›å»ºç»„ä»¶
2. âœ… å®šä¹‰ State å’Œ Request
3. âœ… ä½¿ç”¨æ–°çš„ Agent åˆ›å»ºæ–¹å¼
4. âœ… é…ç½®å‰ç½®å·¥å…·å’Œåç½®å·¥å…·
5. âœ… ç¼–å†™èŠ‚ç‚¹å‡½æ•°
6. âœ… æ„å»ºå·¥ä½œæµå›¾
7. âœ… è°ƒè¯•å’Œæµ‹è¯•
8. âœ… éµå¾ªæœ€ä½³å®è·µ

### å¿«é€Ÿå¼€å§‹æ£€æŸ¥æ¸…å•

- [ ] ä½¿ç”¨ `dfa create --wf_name xxx` åˆ›å»º Workflow
- [ ] å®šä¹‰æˆ–å¤ç”¨ State å’Œ Request
- [ ] åˆ›å»ºå¿…è¦çš„ Agentï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
- [ ] å®šä¹‰å‰ç½®å·¥å…·ï¼ˆ@builder.pre_toolï¼‰
- [ ] å®šä¹‰åç½®å·¥å…·ï¼ˆ@builder.post_toolï¼Œå¦‚æœéœ€è¦ï¼‰
- [ ] å®ç°èŠ‚ç‚¹å‡½æ•°
- [ ] é…ç½®èŠ‚ç‚¹ã€è¾¹å’Œæ¡ä»¶è¾¹
- [ ] ç¼–å†™æµ‹è¯•æ–‡ä»¶
- [ ] è¿è¡Œæµ‹è¯•éªŒè¯
- [ ] æ·»åŠ æ–‡æ¡£æ³¨é‡Š

### å‚è€ƒèµ„æº

- [é¡¹ç›®æ¶æ„æ–‡æ¡£](../guides/architecture.md)
- [Agent å¼€å‘æŒ‡å—](../guides/agent_development.md)
- [å·¥å…·ç³»ç»Ÿæ–‡æ¡£](../guides/tool_system.md)
- [ç¤ºä¾‹ Workflow](../../dataflow_agent/workflow/)

---

**ç¥ä½ ç¼–å†™å‡ºé«˜æ•ˆã€å¯ç»´æŠ¤çš„ Workflowï¼** ğŸš€
