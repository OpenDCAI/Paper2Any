import os
import gradio as gr
from langgraph.graph import StateGraph, START, END

from dataflow_agent.state import DataCollectionRequest, DataCollectionState
from dataflow_agent.agentroles.dataconvertor import universal_data_conversion
from script.run_web_pipeline import web_crawl_collection


def create_web_collection():
    """å­é¡µé¢ï¼šç½‘é¡µæ•°æ®é‡‡é›†ä¸è½¬æ¢ï¼ˆåŸºäº run_web_pipeline å·¥ä½œæµï¼‰"""
    with gr.Blocks() as page:
        gr.Markdown("# ğŸŒ ç½‘é¡µæ•°æ®é‡‡é›†ä¸è½¬æ¢")

        with gr.Row():
            # å·¦ä¾§ï¼šè¾“å…¥åŒºåŸŸ
            with gr.Column():
                gr.Markdown("### é‡‡é›†é…ç½®")
                target = gr.Textbox(
                    label="ç›®æ ‡æè¿°",
                    placeholder="ä¾‹å¦‚ï¼šæ”¶é›† Python ä»£ç ç¤ºä¾‹çš„æ•°æ®é›†",
                    lines=3
                )
                category = gr.Dropdown(
                    label="æ•°æ®ç±»åˆ«",
                    choices=["PT", "SFT"],
                    value="SFT"
                )
                dataset_num_limit = gr.Slider(
                    label="æ•°æ®é›†æ•°é‡ä¸Šé™ï¼ˆæ¯å…³é”®è¯ï¼Œä»…ç”¨äºå‚è€ƒï¼‰",
                    minimum=1,
                    maximum=50,
                    step=1,
                    value=5
                )
                dataset_size_category = gr.Dropdown(
                    label="æ•°æ®é›†å¤§å°èŒƒå›´",
                    choices=["n<1K", "1K<n<10K", "10K<n<100K", "100K<n<1M", "n>1M"],
                    value="1K<n<10K"
                )
                download_dir = gr.Textbox(
                    label="ä¸‹è½½ç›®å½•",
                    value="downloaded_data",
                )
                language = gr.Dropdown(
                    label="æç¤ºè¯è¯­è¨€",
                    choices=["zh", "en"],
                    value="zh"
                )

                gr.Markdown("### LLM é…ç½®")
                chat_api_url = gr.Textbox(
                    label="CHAT_API_URL",
                    value=os.getenv("CHAT_API_URL", "http://123.129.219.111:3000/v1/chat/completions")
                )
                api_key = gr.Textbox(
                    label="CHAT_API_KEY",
                    value=os.getenv("CHAT_API_KEY", ""),
                    type="password"
                )
                model = gr.Textbox(
                    label="CHAT_MODEL",
                    value=os.getenv("CHAT_MODEL", "deepseek-chat")
                )

                gr.Markdown("### å…¶ä»–ç¯å¢ƒé…ç½®")
                hf_endpoint = gr.Textbox(
                    label="HF_ENDPOINT",
                    value=os.getenv("HF_ENDPOINT", "https://hf-mirror.com")
                )
                kaggle_username = gr.Textbox(
                    label="KAGGLE_USERNAME",
                    value=os.getenv("KAGGLE_USERNAME", "")
                )
                kaggle_key = gr.Textbox(
                    label="KAGGLE_KEY",
                    value=os.getenv("KAGGLE_KEY", ""),
                    type="password"
                )

                gr.Markdown("### RAG é…ç½®")
                rag_ebd_model = gr.Textbox(
                    label="RAG_EBD_MODEL",
                    value=os.getenv("RAG_EBD_MODEL", "text-embedding-3-large")
                )
                rag_api_url = gr.Textbox(
                    label="RAG_API_URL",
                    value=os.getenv("RAG_API_URL", "http://123.129.219.111:3000/v1/chat/completions")
                )
                rag_api_key = gr.Textbox(
                    label="RAG_API_KEY",
                    value=os.getenv("RAG_API_KEY", ""),
                    type="password"
                )

                # é«˜çº§é…ç½®åŒºåŸŸï¼ˆå¯æŠ˜å ï¼‰
                with gr.Accordion("âš™ï¸ é«˜çº§é…ç½®", open=False):
                    gr.Markdown("### ç½‘é¡µé‡‡é›†é«˜çº§é…ç½®")
                    max_crawl_cycles_per_task = gr.Slider(
                        label="ä¸‹è½½ä»»åŠ¡æœ€å¤§å¾ªç¯æ¬¡æ•°",
                        minimum=1,
                        maximum=50,
                        step=1,
                        value=10,
                        info="æ§åˆ¶æ¯ä¸ªä¸‹è½½ä»»åŠ¡çš„æœ€å¤§é‡è¯•å¾ªç¯æ¬¡æ•°"
                    )
                    max_crawl_cycles_for_research = gr.Slider(
                        label="ç ”ç©¶é˜¶æ®µæœ€å¤§å¾ªç¯æ¬¡æ•°",
                        minimum=1,
                        maximum=50,
                        step=1,
                        value=15,
                        info="researché˜¶æ®µçš„æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œå…è®¸è®¿é—®æ›´å¤šç½‘ç«™"
                    )
                    search_engine = gr.Dropdown(
                        label="æœç´¢å¼•æ“",
                        choices=["tavily", "duckduckgo", "jina"],
                        value="tavily",
                        info="é€‰æ‹©ç”¨äºæœç´¢çš„å¼•æ“"
                    )
                    use_jina_reader = gr.Checkbox(
                        label="ä½¿ç”¨ Jina Reader",
                        value=True,
                        info="æ˜¯å¦ä½¿ç”¨ Jina Reader æå–ç½‘é¡µç»“æ„åŒ–å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼Œå¿«é€Ÿï¼‰"
                    )
                    enable_rag = gr.Checkbox(
                        label="å¯ç”¨ RAG å¢å¼º",
                        value=True,
                        info="æ˜¯å¦å¯ç”¨ RAG å¢å¼ºï¼ˆæ— è®ºä½¿ç”¨å“ªç§è§£ææ–¹æ³•ï¼Œéƒ½ç”¨ RAG ç²¾ç‚¼å†…å®¹ï¼‰"
                    )
                    concurrent_pages = gr.Slider(
                        label="å¹¶è¡Œå¤„ç†é¡µé¢æ•°",
                        minimum=1,
                        maximum=20,
                        step=1,
                        value=5,
                        info="å¹¶è¡Œå¤„ç†çš„é¡µé¢æ•°é‡ï¼Œå¯æ ¹æ®ç½‘ç»œå’Œæœºå™¨æ€§èƒ½è°ƒæ•´ï¼ˆå»ºè®®3-10ï¼‰"
                    )
                    disable_cache = gr.Checkbox(
                        label="ç¦ç”¨ç¼“å­˜",
                        value=True,
                        info="å¦‚æœå¯ç”¨ï¼Œå°†å®Œå…¨ç¦ç”¨ HuggingFace å’Œ Kaggle çš„ç¼“å­˜ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•å¹¶åœ¨ä¸‹è½½åè‡ªåŠ¨æ¸…ç†"
                    )
                    temp_base_dir = gr.Textbox(
                        label="ä¸´æ—¶ç›®å½•ï¼ˆå¯é€‰ï¼‰",
                        value="",
                        placeholder="ç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤ä¸´æ—¶ç›®å½•",
                        info="è‡ªå®šä¹‰ä¸´æ—¶ç›®å½•è·¯å¾„ï¼Œç”¨äºç¼“å­˜å’Œä¸´æ—¶æ–‡ä»¶"
                    )

                    gr.Markdown("### æ•°æ®è½¬æ¢é«˜çº§é…ç½®")
                    conversion_temperature = gr.Slider(
                        label="è½¬æ¢æ¨¡å‹æ¸©åº¦",
                        minimum=0.0,
                        maximum=2.0,
                        step=0.1,
                        value=0.0,
                        info="æ•°æ®è½¬æ¢æ—¶ä½¿ç”¨çš„æ¨¡å‹æ¸©åº¦å‚æ•°"
                    )
                    conversion_max_tokens = gr.Slider(
                        label="è½¬æ¢æœ€å¤§ Token æ•°",
                        minimum=512,
                        maximum=8192,
                        step=256,
                        value=4096,
                        info="æ•°æ®è½¬æ¢æ—¶çš„æœ€å¤§ token æ•°"
                    )
                    conversion_max_sample_length = gr.Slider(
                        label="æœ€å¤§é‡‡æ ·é•¿åº¦ï¼ˆå­—ç¬¦ï¼‰",
                        minimum=50,
                        maximum=1000,
                        step=50,
                        value=200,
                        info="æ¯ä¸ªå­—æ®µçš„æœ€å¤§é‡‡æ ·é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰"
                    )
                    conversion_num_sample_records = gr.Slider(
                        label="é‡‡æ ·è®°å½•æ•°é‡",
                        minimum=1,
                        maximum=10,
                        step=1,
                        value=3,
                        info="ç”¨äºåˆ†æçš„é‡‡æ ·è®°å½•æ•°é‡"
                    )

                submit_btn = gr.Button("å¼€å§‹ç½‘é¡µé‡‡é›†ä¸è½¬æ¢", variant="primary")

            # å³ä¾§ï¼šè¾“å‡ºåŒºåŸŸ
            with gr.Column():
                with gr.Tab("æ‰§è¡Œæ—¥å¿—"):
                    output_log = gr.Textbox(label="æ—¥å¿—", lines=18)
                with gr.Tab("ç»“æœæ‘˜è¦"):
                    output_json = gr.JSON(label="æ‰§è¡Œç»“æœ")

        async def run_pipeline(
            target_text: str,
            category_val: str,
            dataset_num_limit_val: int,
            dataset_size_category_val: str,
            download_dir_val: str,
            language_val: str,
            chat_api_url_val: str,
            api_key_val: str,
            model_val: str,
            hf_endpoint_val: str,
            kaggle_username_val: str,
            kaggle_key_val: str,
            rag_ebd_model_val: str,
            rag_api_url_val: str,
            rag_api_key_val: str,
            # é«˜çº§é…ç½®å‚æ•°
            max_crawl_cycles_per_task_val: int,
            max_crawl_cycles_for_research_val: int,
            search_engine_val: str,
            use_jina_reader_val: bool,
            enable_rag_val: bool,
            concurrent_pages_val: int,
            disable_cache_val: bool,
            temp_base_dir_val: str,
            conversion_temperature_val: float,
            conversion_max_tokens_val: int,
            conversion_max_sample_length_val: int,
            conversion_num_sample_records_val: int,
        ):
            # æ³¨å…¥/è¦†ç›–è¿è¡Œæ‰€éœ€çš„ç¯å¢ƒå˜é‡
            os.environ["CHAT_API_URL"] = chat_api_url_val or ""
            os.environ["CHAT_API_KEY"] = api_key_val or ""
            os.environ["CHAT_MODEL"] = model_val or ""
            os.environ["HF_ENDPOINT"] = hf_endpoint_val or ""
            os.environ["KAGGLE_USERNAME"] = kaggle_username_val or ""
            os.environ["KAGGLE_KEY"] = kaggle_key_val or ""
            os.environ["RAG_EBD_MODEL"] = rag_ebd_model_val or ""
            os.environ["RAG_API_URL"] = rag_api_url_val or ""
            os.environ["RAG_API_KEY"] = rag_api_key_val or ""
            
            # è®¾ç½®é«˜çº§é…ç½®ç›¸å…³ç¯å¢ƒå˜é‡
            if disable_cache_val:
                os.environ["DF_DISABLE_CACHE"] = "true"
            else:
                os.environ.pop("DF_DISABLE_CACHE", None)
            
            if temp_base_dir_val:
                os.environ["DF_TEMP_DIR"] = temp_base_dir_val

            # ç»„è£…è¯·æ±‚
            req = DataCollectionRequest(
                target=target_text,
                category=category_val,
                dataset_num_limit=int(dataset_num_limit_val),
                dataset_size_category=dataset_size_category_val,
                download_dir=download_dir_val,
                chat_api_url=chat_api_url_val,
                api_key=api_key_val,
                model=model_val,
                language=language_val,
            )

            # æ„å»ºå·¥ä½œæµ
            state = DataCollectionState(request=req)

            # åˆ›å»ºåŒ…è£…å‡½æ•°ä»¥ä¼ é€’é«˜çº§é…ç½®å‚æ•°
            async def web_crawl_collection_wrapper(state: DataCollectionState) -> DataCollectionState:
                return await web_crawl_collection(
                    state,
                    max_crawl_cycles_per_task=int(max_crawl_cycles_per_task_val),
                    max_crawl_cycles_for_research=int(max_crawl_cycles_for_research_val),
                    search_engine=search_engine_val,
                    use_jina_reader=use_jina_reader_val,
                    enable_rag=enable_rag_val,
                    concurrent_pages=int(concurrent_pages_val),
                )
            
            async def universal_data_conversion_wrapper(state: DataCollectionState) -> DataCollectionState:
                return await universal_data_conversion(
                    state,
                    model_name=model_val or None,
                    temperature=float(conversion_temperature_val),
                    max_tokens=int(conversion_max_tokens_val),
                    max_sample_length=int(conversion_max_sample_length_val),
                    num_sample_records=int(conversion_num_sample_records_val),
                )

            graph_builder = StateGraph(DataCollectionState)
            graph_builder.add_node("web_crawl_collection", web_crawl_collection_wrapper)
            graph_builder.add_node("universal_data_conversion", universal_data_conversion_wrapper)
            graph_builder.add_edge(START, "web_crawl_collection")
            graph_builder.add_edge("web_crawl_collection", "universal_data_conversion")
            graph_builder.add_edge("universal_data_conversion", END)
            graph = graph_builder.compile()

            # æ‰§è¡Œ
            log_lines = []
            log_lines.append("=" * 60)
            log_lines.append("å¼€å§‹æ‰§è¡Œç½‘é¡µé‡‡é›†ä¸è½¬æ¢å·¥ä½œæµ")
            log_lines.append("=" * 60)
            log_lines.append(f"ç›®æ ‡: {req.target}")
            log_lines.append(f"ç±»åˆ«: {req.category}")
            log_lines.append(f"ä¸‹è½½ç›®å½•: {req.download_dir}")
            log_lines.append("\nã€ç½‘é¡µé‡‡é›†é…ç½®ã€‘")
            log_lines.append(f"  - æœç´¢å¼•æ“: {search_engine_val}")
            log_lines.append(f"  - ä»»åŠ¡æœ€å¤§å¾ªç¯æ¬¡æ•°: {max_crawl_cycles_per_task_val}")
            log_lines.append(f"  - ç ”ç©¶é˜¶æ®µæœ€å¤§å¾ªç¯æ¬¡æ•°: {max_crawl_cycles_for_research_val}")
            log_lines.append(f"  - ä½¿ç”¨ Jina Reader: {'æ˜¯' if use_jina_reader_val else 'å¦'}")
            log_lines.append(f"  - å¯ç”¨ RAG: {'æ˜¯' if enable_rag_val else 'å¦'}")
            log_lines.append(f"  - å¹¶è¡Œé¡µé¢æ•°: {concurrent_pages_val}")
            log_lines.append(f"  - ç¦ç”¨ç¼“å­˜: {'æ˜¯' if disable_cache_val else 'å¦'}")
            log_lines.append("\nã€æ•°æ®è½¬æ¢é…ç½®ã€‘")
            log_lines.append(f"  - æ¨¡å‹æ¸©åº¦: {conversion_temperature_val}")
            log_lines.append(f"  - æœ€å¤§ Token æ•°: {conversion_max_tokens_val}")
            log_lines.append(f"  - æœ€å¤§é‡‡æ ·é•¿åº¦: {conversion_max_sample_length_val}")
            log_lines.append(f"  - é‡‡æ ·è®°å½•æ•°: {conversion_num_sample_records_val}")
            log_lines.append("=" * 60)

            final_state: DataCollectionState = await graph.ainvoke(state)

            log_lines.append("æµç¨‹æ‰§è¡Œå®Œæˆï¼")

            result = {
                "download_dir": req.download_dir,
                "processed_output": os.path.join(req.download_dir, "processed_output"),
                "category": req.category,
                "language": req.language,
                "chat_model": req.model,
            }

            return "\n".join(log_lines), result

        submit_btn.click(
            run_pipeline,
            inputs=[
                target,
                category,
                dataset_num_limit,
                dataset_size_category,
                download_dir,
                language,
                chat_api_url,
                api_key,
                model,
                hf_endpoint,
                kaggle_username,
                kaggle_key,
                rag_ebd_model,
                rag_api_url,
                rag_api_key,
                # é«˜çº§é…ç½®å‚æ•°
                max_crawl_cycles_per_task,
                max_crawl_cycles_for_research,
                search_engine,
                use_jina_reader,
                enable_rag,
                concurrent_pages,
                disable_cache,
                temp_base_dir,
                conversion_temperature,
                conversion_max_tokens,
                conversion_max_sample_length,
                conversion_num_sample_records,
            ],
            outputs=[output_log, output_json],
        )

    return page


